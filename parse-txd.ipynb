{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the log files into multiple valid JSON files\n",
    "\n",
    "|Author|Christopher Mortimer|\n",
    "|---|---|\n",
    "|Date|2020-06-14|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the json paackage for easy parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format of a txd\n",
    "TXD is STR's table definition markup language\n",
    " \n",
    " ```sql\n",
    " ROW\n",
    "     DIM\n",
    "         RCD \"Professions\" FACTTABLE \"All Professions All Years\"\n",
    "     END DIM\n",
    "     AXIS_MAP\n",
    "     END AXIS_MAP\n",
    " END ROW\n",
    " COLUMN\n",
    "     DIM\n",
    "         RCD \"Year\" FACTTABLE \"All Professions All Years\"\n",
    "     END DIM\n",
    "     AXIS_MAP\n",
    "     END AXIS_MAP\n",
    " END COLUMN\n",
    " END TABLE\n",
    "  ```\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON check function\n",
    "def isJson(myjson):\n",
    "  try:\n",
    "    json_object = json.loads(myjson)\n",
    "  except ValueError as e:\n",
    "    return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the parseFile() function\n",
    "\n",
    "Parses each log line of a log file and extracts the rows and columns in the TXD cross tabulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFile(filename, debugFlag):\n",
    "  # the JSON file\n",
    "  f = open(\"./data/\" + env + \"/\" + filename, \"r+\")\n",
    "  ## Loop through each line in the file\n",
    "  for idx, x in enumerate(f):\n",
    "    if debugFlag:\n",
    "      print(idx)\n",
    "    if isJson(x):\n",
    "      jsonLine = json.loads(x)\n",
    "      ## Check the keys in the line, if the line has a txd then parse\n",
    "      jsonKeys=jsonLine.keys()\n",
    "      if \"txd\" in jsonKeys:\n",
    "        # Get the txd field\n",
    "        txd=jsonLine[\"txd\"]\n",
    "        # txd is STR table definition markup, the table part is after \\n\\nTABLE\\n\n",
    "        if \"\\n\\nTABLE\\n\" in txd:\n",
    "          column = ''\n",
    "          row = ''\n",
    "          table=txd.split('\\n\\nTABLE\\n')[1]\n",
    "          # Lets just get the DIMs\n",
    "          if \"ROW\\n\\tDIM\\n\\t\\tRCD\" in table:\n",
    "            # how many rows?\n",
    "            #print(\"rows: \" + str(len(table.split('ROW\\n\\tDIM\\n\\t\\tRCD'))-1))\n",
    "            row=table.split('ROW\\n\\tDIM\\n\\t\\tRCD')[1].split(\"END\")[0]\n",
    "            if \"ORDER\" in row:\n",
    "              #print(\"found order\")\n",
    "              row=row.split(\"ORDER\")[0]\n",
    "          if \"COLUMN\\n\\tDIM\\n\\t\\tRCD\" in table:\n",
    "            #print(\"columns: \" + str(len(table.split('COLUMN\\n\\tDIM\\n\\t\\tRCD'))-1))\n",
    "            column=table.split('COLUMN\\n\\tDIM\\n\\t\\tRCD')[1].split(\"END\")[0]\n",
    "            if \"Summation Options\" in column:\n",
    "              #print(\"found summation\")\n",
    "              column=column.split(\"Summation Options\")[0]\n",
    "            if \"ORDER\" in column:\n",
    "              #print(\"found order\")\n",
    "              column=column.split(\"ORDER\")[0]\n",
    "          ## Add another two json fields for row and column\n",
    "          jsonLine['txd'] = 'truncate-save-space'\n",
    "          jsonLine['row'] = row.strip()\n",
    "          jsonLine['column'] = column.strip()\n",
    "      if debugFlag:\n",
    "        print(jsonLine)\n",
    "      else:\n",
    "        ## Create new file\n",
    "        fProc = open(\"./data/\" + env + \"/pythonProc/\" + filename + '.' + str(idx) + '.json', \"w\")\n",
    "        fProc.write(json.dumps(jsonLine))\n",
    "        fCsv = open(\"./data/\" + env + '.csv', \"a+\")\n",
    "        csvLine = ','.join([str(idx),env,filename,\"./data/\" + env + \"/pythonProc/\" + filename + '.' + str(idx) + '.json'+\"\\n\"])\n",
    "        fCsv.write(csvLine)\n",
    "    else:\n",
    "      print('not json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "## Unit test for parsing a file\n",
    "env = \"test\"\n",
    "filename1 = \"2020-05-14-superweb2.log\"\n",
    "parseFile(filename1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the loopFiles() function\n",
    "\n",
    "Gets a list of all the files in a directory and calls the parseFile() function on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loopFiles(dirname,debugFlag):\n",
    "  fCsv = open(\"./data/\" + env + '.csv', \"w+\")\n",
    "  fCsv.write('')\n",
    "  directory = os.fsencode(dirname)\n",
    "  for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".log\"): \n",
    "      if debugFlag:\n",
    "        print(filename)\n",
    "        parseFile(filename,1)\n",
    "      else:\n",
    "        parseFile(filename,0)\n",
    "    else:\n",
    "      print(filename + \" is not a log file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "proc is not a log file\npythonProc is not a log file\n"
    }
   ],
   "source": [
    "## unit test for loopFiles\n",
    "env = \"test\"\n",
    "dirname = \"./data/\" + env + \"/\"\n",
    "loopFiles(dirname,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bite8bb320fe19c451f8dd7edcd0f4d1be1",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}